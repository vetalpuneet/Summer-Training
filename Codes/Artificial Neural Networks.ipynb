{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = []\n",
    "train_label = []\n",
    "for i in range(1000):\n",
    "    younger_ages = randint(13, 64)\n",
    "    train_sample.append(younger_ages)\n",
    "    train_label.append(0)\n",
    "    \n",
    "    older_ages = randint(65, 100)\n",
    "    train_sample.append(older_ages)\n",
    "    train_label.append(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 86, 63, 99, 28, 74, 45, 100, 60, 91, 20, 94, 25, 67, 58, 82, 61, 95, 50, 91, 63, 92, 44, 72, 20, 98, 27, 71, 44, 67, 59, 75, 59, 68, 56, 81, 21, 73, 45, 95, 18, 85, 47, 83, 64, 85, 39, 94, 36, 98, 20, 83, 21, 85, 58, 90, 15, 98, 33, 83, 35, 80, 26, 78, 47, 84, 30, 68, 19, 67, 27, 80, 40, 68, 40, 88, 51, 88, 59, 85, 46, 66, 20, 96, 55, 73, 25, 85, 23, 91, 48, 68, 50, 70, 29, 97, 64, 87, 44, 91, 58, 84, 54, 69, 30, 67, 14, 96, 45, 75, 22, 84, 36, 65, 54, 66, 35, 89, 48, 89, 36, 94, 25, 98, 55, 95, 56, 71, 30, 95, 54, 86, 52, 65, 33, 85, 56, 68, 54, 86, 19, 72, 41, 86, 59, 67, 30, 77, 46, 96, 17, 79, 25, 75, 34, 87, 53, 91, 21, 68, 53, 88, 32, 67, 32, 91, 19, 91, 16, 87, 55, 89, 52, 69, 13, 83, 46, 75, 60, 79, 54, 73, 46, 79, 31, 90, 23, 71, 42, 84, 53, 68, 58, 82, 41, 90, 53, 92, 46, 81, 59, 97, 40, 66, 45, 89, 28, 79, 61, 72, 19, 71, 35, 80, 38, 100, 23, 83, 23, 93, 14, 89, 29, 72, 42, 83, 57, 87, 20, 97, 50, 95, 51, 77, 47, 84, 24, 77, 56, 95, 40, 82, 53, 74, 36, 70, 19, 85, 15, 66, 48, 80, 48, 92, 25, 65, 15, 77, 42, 73, 40, 79, 59, 65, 52, 94, 44, 82, 13, 85, 23, 88, 47, 87, 58, 85, 24, 73, 49, 75, 19, 76, 44, 75, 53, 75, 38, 65, 42, 80, 40, 95, 23, 89, 39, 92, 13, 84, 42, 100, 16, 90, 43, 96, 51, 70, 25, 78, 60, 93, 20, 89, 58, 74, 15, 91, 43, 76, 54, 72, 61, 75, 20, 89, 57, 83, 33, 67, 53, 92, 52, 83, 55, 95, 56, 81, 26, 65, 38, 91, 57, 88, 39, 73, 35, 97, 46, 90, 29, 89, 51, 75, 28, 89, 43, 84, 45, 68, 29, 72, 31, 88, 28, 78, 51, 87, 42, 65, 37, 88, 19, 94, 62, 92, 30, 82, 33, 98, 13, 81, 35, 82, 53, 73, 34, 96, 23, 77, 51, 72, 35, 65, 58, 91, 26, 65, 54, 76, 30, 74, 62, 83, 47, 69, 26, 66, 35, 67, 63, 100, 35, 94, 25, 86, 60, 69, 20, 86, 55, 93, 39, 88, 28, 65, 57, 76, 39, 100, 29, 98, 14, 76, 55, 81, 64, 86, 33, 73, 24, 74, 53, 99, 49, 79, 34, 94, 20, 80, 54, 65, 60, 91, 44, 97, 40, 97, 45, 92, 30, 96, 48, 94, 21, 71, 60, 70, 15, 79, 58, 72, 20, 87, 64, 100, 57, 84, 37, 78, 30, 78, 32, 72, 28, 90, 52, 94, 46, 83, 29, 93, 64, 87, 40, 73, 47, 72, 47, 93, 25, 88, 17, 79, 21, 87, 26, 75, 43, 72, 44, 88, 20, 84, 21, 67, 14, 79, 27, 78, 54, 69, 55, 67, 61, 68, 64, 78, 33, 73, 19, 75, 64, 78, 15, 71, 61, 93, 26, 88, 20, 79, 36, 76, 32, 75, 45, 72, 20, 89, 13, 88, 44, 66, 61, 89, 29, 73, 39, 85, 40, 84, 43, 70, 61, 96, 58, 85, 20, 70, 51, 98, 24, 89, 49, 83, 15, 71, 51, 69, 62, 83, 60, 73, 57, 78, 32, 77, 40, 93, 64, 69, 63, 86, 21, 66, 26, 78, 36, 77, 34, 84, 27, 85, 49, 73, 14, 88, 33, 73, 49, 70, 43, 77, 36, 81, 15, 71, 39, 99, 43, 89, 41, 93, 23, 93, 41, 86, 26, 77, 44, 92, 62, 70, 23, 74, 26, 79, 52, 92, 18, 85, 18, 77, 22, 82, 45, 82, 54, 74, 29, 82, 51, 69, 55, 79, 41, 93, 60, 72, 60, 82, 16, 66, 25, 78, 17, 90, 58, 89, 39, 89, 51, 66, 64, 71, 45, 76, 15, 87, 36, 97, 47, 89, 47, 86, 54, 76, 33, 84, 23, 92, 38, 76, 14, 76, 17, 81, 32, 68, 53, 67, 19, 69, 57, 71, 19, 65, 30, 82, 53, 89, 60, 83, 57, 91, 59, 87, 41, 86, 17, 72, 24, 80, 13, 74, 37, 86, 35, 86, 57, 97, 38, 78, 55, 89, 23, 94, 30, 90, 29, 80, 13, 99, 45, 91, 33, 71, 27, 83, 53, 75, 35, 87, 22, 78, 29, 84, 13, 71, 20, 77, 62, 88, 53, 76, 39, 73, 31, 87, 59, 85, 34, 67, 31, 87, 49, 75, 55, 82, 13, 71, 57, 77, 48, 91, 29, 90, 57, 77, 50, 85, 40, 90, 59, 88, 61, 68, 53, 94, 35, 85, 18, 79, 60, 94, 32, 75, 59, 70, 24, 70, 62, 77, 40, 90, 36, 97, 58, 97, 51, 82, 22, 92, 39, 77, 41, 82, 33, 68, 62, 98, 28, 71, 47, 68, 50, 66, 45, 93, 42, 87, 56, 70, 57, 98, 24, 86, 54, 88, 25, 87, 40, 68, 31, 81, 31, 80, 28, 96, 53, 66, 63, 87, 27, 79, 64, 76, 64, 90, 42, 94, 27, 70, 21, 89, 33, 93, 22, 89, 36, 90, 30, 80, 33, 78, 37, 87, 55, 93, 33, 66, 38, 75, 35, 73, 14, 82, 21, 95, 55, 98, 38, 96, 45, 76, 39, 98, 24, 90, 42, 69, 13, 84, 45, 82, 28, 80, 53, 94, 17, 92, 47, 85, 42, 84, 47, 87, 46, 90, 58, 88, 13, 78, 18, 68, 14, 77, 57, 65, 33, 100, 34, 70, 50, 71, 56, 71, 53, 76, 58, 67, 39, 86, 18, 70, 58, 79, 39, 87, 41, 88, 58, 98, 19, 70, 59, 80, 30, 95, 23, 72, 35, 92, 31, 77, 63, 70, 23, 70, 47, 93, 30, 80, 35, 72, 48, 70, 20, 83, 43, 88, 15, 65, 60, 95, 27, 98, 36, 96, 59, 65, 33, 81, 55, 86, 22, 78, 34, 73, 51, 73, 64, 83, 27, 83, 37, 70, 36, 90, 37, 81, 59, 66, 53, 98, 23, 85, 16, 76, 43, 75, 19, 76, 39, 67, 21, 94, 35, 72, 17, 72, 45, 90, 25, 66, 51, 87, 55, 73, 16, 77, 49, 89, 33, 89, 62, 99, 56, 93, 49, 91, 14, 82, 53, 83, 52, 94, 16, 80, 48, 98, 49, 95, 24, 66, 13, 85, 49, 68, 56, 65, 45, 69, 26, 75, 40, 91, 34, 77, 48, 78, 48, 92, 56, 97, 18, 68, 38, 78, 43, 89, 52, 87, 18, 87, 18, 98, 50, 68, 47, 79, 18, 74, 50, 100, 13, 73, 47, 74, 45, 77, 38, 66, 14, 80, 14, 87, 22, 92, 41, 96, 48, 68, 62, 67, 38, 74, 59, 81, 41, 74, 16, 67, 26, 73, 28, 85, 16, 70, 33, 100, 20, 85, 21, 78, 19, 81, 49, 70, 50, 79, 14, 97, 59, 67, 26, 66, 33, 80, 38, 81, 38, 71, 42, 79, 24, 68, 36, 93, 61, 85, 27, 82, 57, 71, 33, 85, 20, 87, 21, 99, 20, 100, 59, 78, 25, 86, 45, 84, 51, 77, 58, 99, 59, 92, 16, 85, 25, 97, 13, 85, 54, 94, 39, 87, 56, 100, 50, 65, 39, 79, 24, 90, 56, 70, 20, 66, 58, 92, 13, 75, 57, 99, 33, 65, 57, 96, 55, 90, 42, 70, 56, 74, 62, 86, 63, 98, 54, 73, 49, 95, 62, 65, 59, 81, 25, 70, 20, 75, 14, 78, 53, 66, 18, 75, 13, 100, 25, 95, 46, 89, 36, 89, 18, 78, 21, 100, 52, 71, 58, 78, 15, 67, 28, 84, 34, 82, 56, 97, 58, 75, 58, 80, 39, 87, 48, 82, 55, 78, 26, 92, 55, 88, 60, 67, 46, 70, 30, 94, 61, 71, 30, 85, 56, 84, 31, 86, 51, 85, 20, 68, 50, 69, 54, 88, 15, 67, 26, 83, 25, 97, 35, 92, 29, 70, 26, 91, 47, 86, 52, 79, 53, 84, 30, 88, 36, 94, 63, 83, 33, 71, 58, 93, 29, 78, 13, 70, 27, 92, 36, 77, 20, 86, 40, 73, 15, 90, 42, 100, 26, 93, 32, 70, 50, 98, 60, 85, 33, 72, 32, 97, 22, 98, 31, 73, 28, 94, 27, 74, 17, 97, 61, 84, 26, 81, 64, 72, 20, 88, 32, 99, 59, 91, 30, 96, 55, 78, 28, 86, 48, 65, 37, 80, 17, 76, 34, 72, 49, 97, 48, 82, 23, 69, 15, 90, 30, 100, 34, 85, 21, 91, 16, 78, 43, 82, 25, 72, 25, 70, 50, 66, 60, 78, 50, 70, 16, 73, 52, 77, 49, 93, 35, 99, 49, 70, 21, 70, 17, 88, 29, 68, 56, 91, 54, 92, 38, 92, 57, 71, 17, 100, 34, 75, 42, 79, 34, 72, 40, 94, 63, 65, 40, 98, 51, 77, 38, 90, 18, 77, 15, 81, 19, 68, 32, 85, 47, 93, 46, 82, 17, 98, 40, 87, 17, 97, 26, 80, 42, 86, 13, 100, 23, 70, 61, 83, 24, 88, 14, 66, 47, 85, 51, 100, 56, 97, 39, 65, 47, 93, 53, 90, 59, 70, 13, 67, 31, 72, 44, 88, 55, 89, 60, 83, 44, 99, 13, 85, 45, 75, 58, 67, 21, 87, 16, 94, 34, 74, 28, 97, 23, 82, 35, 79, 21, 68, 14, 88, 41, 99, 13, 73, 39, 98, 49, 69, 31, 81, 58, 71, 31, 66, 30, 82, 55, 99, 16, 83, 42, 99, 35, 85, 40, 96, 44, 66, 21, 90, 49, 74, 47, 68, 35, 75, 36, 84, 56, 66, 32, 71, 47, 90, 59, 88, 24, 99, 63, 77, 64, 84, 50, 93, 27, 80, 57, 87, 50, 95, 43, 77, 47, 67, 29, 88, 15, 85, 59, 78, 44, 89, 48, 65, 30, 98, 14, 92, 46, 92, 40, 88, 42, 96, 61, 68, 54, 100, 33, 67, 47, 84, 25, 87, 62, 94, 33, 91, 43, 75, 51, 84, 43, 68, 20, 74, 47, 96, 23, 92, 32, 71, 17, 99, 35, 70, 16, 87, 20, 77, 14, 90, 41, 78, 17, 98, 36, 75, 14, 67, 24, 77, 56, 97, 27, 77, 44, 75, 41, 90, 63, 68, 26, 67, 29, 93, 60, 69, 53, 83, 16, 65, 32, 76, 27, 75, 16, 87, 16, 97, 36, 83, 17, 69, 16, 76, 13, 94, 26, 95, 55, 71, 23, 92, 54, 73, 63, 77, 37, 76, 62, 90, 33, 92, 36, 98, 35, 78, 33, 73, 43, 70, 26, 75, 39, 100, 57, 80, 32, 90, 58, 75, 17, 72, 41, 65, 56, 68, 23, 92, 17, 91, 37, 96, 15, 77, 39, 90, 23, 67, 34, 89, 48, 98, 52, 86, 33, 75, 55, 77, 59, 81, 53, 66, 24, 69, 23, 66, 47, 73, 30, 81, 42, 81, 53, 72, 55, 83, 29, 80, 53, 79, 54, 96, 47, 94, 58, 95, 58, 74, 56, 82, 49, 86, 39, 80, 15, 89, 49, 96, 41, 70, 38, 81, 62, 94, 24, 80, 50, 82, 33, 87, 15, 78, 25, 71, 42, 75, 51, 70, 58, 88, 39, 82, 20, 74, 47, 95, 54, 91, 59, 97, 17, 100, 37, 67, 51, 95, 36, 95, 23, 70, 16, 100, 46, 88, 57, 76, 52, 88, 21, 93, 56, 77, 15, 75, 18, 90, 23, 87, 30, 90, 31, 100, 55, 85, 50, 78, 56, 78, 50, 73, 31, 90, 34, 86, 42, 75, 29, 95, 27, 65, 43, 69, 56, 89, 48, 85, 21, 100, 37, 96, 39, 67, 36, 74, 33, 76, 30, 68, 48, 78, 42, 82, 37, 89, 23, 85, 39, 66, 55, 94, 20, 97, 49, 97, 58, 91, 27, 83, 13, 70, 15, 87, 15, 78, 45, 86, 13, 100, 33, 94, 28, 91, 61, 67, 31, 84, 27, 85, 54, 77, 49, 77, 44, 69, 43, 77, 58, 67, 53, 87, 51, 85, 37, 68, 59, 95, 53, 80, 30, 98, 62, 66]\n"
     ]
    }
   ],
   "source": [
    "print(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = np.array(train_sample)\n",
    "train_label = np.array(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 86, 63, ..., 98, 62, 66])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaler_train_sample = scaler.fit_transform(train_sample.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Dense(16, input_dim = 1, activation = 'relu'), Dense(32, activation = 'relu'), Dense(2, activation = 'softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need to compile becuuse it helps to change the weights assign to neurons\n",
    "model.compile(Adam(lr = 0.001), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 1s 387us/step - loss: 0.7332 - acc: 0.6050\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 0s 175us/step - loss: 0.5136 - acc: 0.7555\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 0s 174us/step - loss: 0.4314 - acc: 0.8340\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 0s 173us/step - loss: 0.3730 - acc: 0.8700\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 0s 178us/step - loss: 0.3069 - acc: 0.9045\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 0s 189us/step - loss: 0.2670 - acc: 0.9215\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 0s 173us/step - loss: 0.2293 - acc: 0.9390\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 0s 174us/step - loss: 0.1981 - acc: 0.9435\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 0s 172us/step - loss: 0.1633 - acc: 0.9590\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 0s 172us/step - loss: 0.1567 - acc: 0.9530\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1925a43400>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_sample, train_label, 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = []\n",
    "test_label = []\n",
    "for i in range(500):\n",
    "    younger_ages = randint(13, 64)\n",
    "    test_sample.append(younger_ages)\n",
    "    test_label.append(0)\n",
    "    \n",
    "    older_ages = randint(65, 100)\n",
    "    test_sample.append(older_ages)\n",
    "    test_label.append(1)\n",
    "\n",
    "test_sample = np.array(train_sample)\n",
    "test_label = np.array(train_label)   \n",
    "\n",
    "test_sample_output = model.predict_classes(test_sample, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 974,   26],\n",
       "       [   0, 1000]], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cn = confusion_matrix(test_label, test_sample_output)\n",
    "cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
